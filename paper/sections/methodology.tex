% Methodology Section
\section{Methodology}
\label{sec:methodology}

% System overview
We present \systemname{}, a multimodal RAG system for disaster impact assessment. %Figure~\ref{fig:system_architecture} provides an overview of our architecture. %TODO: add figure reference

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/system_architecture.png}
    \caption{Overview of the \systemname{} architecture. Our system ingests multimodal data (satellite imagery, social media, 311 calls, sensors), retrieves relevant context, and employs a split-pipeline approach with separate text and visual analyzers before fusing results.}
    \label{fig:system_architecture}
\end{figure}

\subsection{Data Sources and Preprocessing}
\label{sec:data_sources}

Our system integrates four primary data sources for Hurricane Harvey (August-September 2017):

\paragraph{Satellite Imagery.}
We use high-resolution aerial imagery from NOAA's Emergency Response Imagery \todo{cite}. The dataset contains approximately 3,500 tiles covering the Greater Houston metropolitan area at 0.5m resolution. Images are indexed by geographic coordinates and acquisition date.

\paragraph{Visual-Text Bridging.}
To enable semantic retrieval of visual data, we leveraged \textbf{Gemini 2.0 Flash Verified} to generate descriptive captions for all \textbf{3,507 aerial image tiles}. These captions are indexed as searchable text documents, allowing the RAG system to retrieve imagery based on textual descriptions of damage (e.g., ``submerged houses'').

\paragraph{Social Media (Twitter/X).}
We implemented a strict filtering pipeline for the 27 million raw tweets collected during Hurricane Harvey to improve signal-to-noise ratio. The process involved: (1) \textbf{De-Duplication}: Removed retweets (approx. 57\% of data); (2) \textbf{Content Filters}: Applied an \textit{Allow List} (e.g., ``flood'', ``rescue'') and a \textit{Block List} (e.g., ``spotify'', ``music'') to remove irrelevant chatter; and (3) \textbf{Spam Removal}: Filtered posts with excessive hashtags/URLs. This reduced the corpus to $\sim$450,000 highly relevant unique tweets ($\sim$1.7\% acceptance rate).

\paragraph{311 Emergency Calls.}
We obtain records from the City of Houston's 311 service system, including reports of flooding, debris, and infrastructure damage. The dataset contains 26,107 records from August 20--September 10, 2017, covering 125 unique ZIP codes in the urban Houston area.


\paragraph{Rainfall Sensors.}
We incorporate data from Harris County Flood Control District rain gauges. To provide localized context, we map each target ZIP code to the nearest available sensor using a centroid-based nearest neighbor lookup, retrieving hourly precipitation measurements for the relevant time window.

\subsection{Multimodal Retrieval}
\label{sec:retrieval}

Given a query specifying a ZIP code and time window, our retrieval system identifies the most relevant context from each data source.

\paragraph{Text Retrieval.}
We employ a hybrid retrieval strategy that combines dense and sparse methods with a reranking stage. For dense retrieval, we generate text embeddings using Sentence-BERT to capture semantic similarity. This is complemented by BM25-based sparse retrieval for keyword matching. Finally, a cross-encoder reranker refines the top candidates to optimize precision.

\paragraph{Visual Retrieval.}
For satellite imagery, searches first attempt to find tiles strictly within the target ZIP code polygon. If insufficient imagery is found, the system falls back to a spatial radius search (e.g., 5km) to retrieve relevant nearby tiles from the same acquisition period.

\subsection{Split-Pipeline Architecture}
\label{sec:split_pipeline}

A key design decision in \systemname{} is the separation of text and visual reasoning into distinct analysis pipelines.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/split_pipeline.png}
    \caption{Split-pipeline architecture with Visual Additive Fusion. Text analysis serves as the primary signal, while visual analysis provides additive confirmation.}
    \label{fig:split_pipeline}
\end{figure}

\paragraph{Text Analyst.}
The Text Analyst module processes retrieved text snippets---including tweets, 311 calls, and sensor readings---and generates a structured analysis, serving as the primary evidence source for local impact.

\paragraph{Visual Analyst.}
The Visual Analyst module processes retrieved satellite imagery tiles to produce a comprehensive visual assessment of flood extent and structural damage.

\paragraph{Fusion Engine (Visual Additive).}
We employ a \textit{Visual Additive} fusion strategy designed to robustly handle temporal misalignments between peak-flood text reports and post-flood snapshot imagery. Text evidence ($E_{text}$) serves as the primary signal for flood extent (Hazard). Visual evidence ($E_{visual}$) is strictly additive and prioritized for structural damage (Consequence):
\begin{equation}
    Score_{final} = \text{Norm}(Score(E_{text}) + \lambda \cdot \mathbb{I}(E_{visual} \text{ confirms damage}))
\end{equation}
This design addresses the "snapshot vs. peak" problem: a clean satellite image taken days after the peak flood should not veto valid text reports of flooding (which occurred earlier), but visible structural damage (debris, blue tarps) serves as a lasting and reliable confirmation signal.

% NOTE: LLM-as-a-Judge evaluation is implemented but not used in current experiments.
% This section is commented out for now and can be re-enabled for future work.

% \subsection{LLM-as-a-Judge Evaluation}
% \label{sec:llm_judge}
% 
% To evaluate response quality beyond quantitative accuracy, we employ multiple LLM judges to assess:
% 
% \paragraph{Faithfulness.}
% Whether claims in the response are supported by the retrieved context:
% \begin{equation}
%     \text{Faithfulness} = \frac{|\text{Supported Claims}|}{|\text{All Claims}|}
% \end{equation}
% 
% \paragraph{Relevance.}
% Whether the response addresses the query:
% \begin{equation}
%     \text{Relevance} = \text{Judge}(Q, A) \in [0, 1]
% \end{equation}
% 
% \input{tables/judges}
