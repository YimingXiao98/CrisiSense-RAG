% Main LaTeX file for Multimodal RAG Paper
% Using NeurIPS 2024 style (can switch to ACL, AAAI, etc.)
\documentclass{article}

% Required packages
\usepackage[preprint]{neurips_2024}  % Change to [final] for camera-ready
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{array}
\usepackage{makecell}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}

% Custom colors
\definecolor{modblue}{RGB}{31, 119, 180}
\definecolor{modgreen}{RGB}{44, 160, 44}
\definecolor{modred}{RGB}{214, 39, 40}

% Custom commands
\newcommand{\systemnameraw}{HarveyRAG}
\newcommand{\systemname}{\textsc{\systemnameraw}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\fixme}[1]{\textcolor{orange}{[FIXME: #1]}}

\title{Multimodal Retrieval-Augmented Generation for \\
Disaster Impact Assessment: \\
A Case Study on Hurricane Harvey}

\author{
  Author One\thanks{Equal contribution} \\
  Department of Computer Science\\
  University Name\\
  \texttt{author1@university.edu} \\
  \And
  Author Two\footnotemark[1] \\
  Department of Computer Science\\
  University Name\\
  \texttt{author2@university.edu} \\
  \And
  Author Three \\
  Department Name\\
  Institution Name\\
  \texttt{author3@institution.edu} \\
}

\begin{document}

\maketitle

\begin{abstract}
    Accurate and timely disaster impact assessment is critical for effective emergency response and resource allocation. We present \systemname{}, a multimodal retrieval-augmented generation (RAG) system that integrates satellite imagery, social media posts, 311 emergency call records, and sensor data to assess flood impact during natural disasters. Our system employs a split-pipeline architecture that separates text and visual reasoning, enabling the use of specialized models for each modality. We evaluate \systemname{} on Hurricane Harvey (2017), comparing model predictions against FEMA flood depth measurements across 50 ZIP codes in the Greater Houston area. Our experiments demonstrate that multimodal context significantly reduces prediction error compared to text-only baselines, with spatial imagery providing critical calibration for text-based damage reports. We further analyze the contribution of different modalities and discuss implications for real-time disaster response systems.
\end{abstract}

% Include sections
\input{sections/introduction}
\input{sections/related_work}
\input{sections/methodology}
\input{sections/experiments}
\input{sections/results}
\input{sections/analysis}
\input{sections/conclusion}

\bibliography{references}
\bibliographystyle{plainnat}

\appendix
\input{sections/appendix}

\end{document}
